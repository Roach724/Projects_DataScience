{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.7 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "004de6046f1b3d314f33fdb43a2dc798b2646e5600efd8df5066c8b63a00ff6d"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from typing import Dict,Text\n",
    "import warnings\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import DeepFM_v2offline as dfm\n",
    "import seaborn as sns\n",
    "from RFM import RFM\n",
    "import io\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#max=11560351\n",
    "#deepfm=tf.keras.models.load_model('E:\\\\kyk-ml\\\\model\\\\DeepFM')\n",
    "#prep=tf.keras.models.load_model('E:\\\\kyk-ml\\\\model\\\\DeepFM\\\\Preprocess')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x00000229E5A203A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x00000229E5A1B4C0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x00000229E5A27D30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x00000229D9269EE0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x00000229E5A2ED30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x00000229E5A2E0D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "#load fundamental log data\n",
    "X=pd.read_csv('E:\\\\dataset\\\\user_log_rs.csv',usecols=[1,2,3,4,5,6,7])\n",
    "group=X.groupby(['item_id'],as_index=False)['user_id'].agg('count').sort_values(by='user_id',ascending=False)\n",
    "group['weight']=group['user_id']/len(X)\n",
    "group['weight']=-np.log(group['weight'])\n",
    "group.drop(columns=['user_id'],inplace=True)\n",
    "X=X.merge(group,on='item_id',how='inner')\n",
    "y=X.pop('label').values\n",
    "sample_weight=X.pop('weight').values\n",
    "X=X.to_dict(orient='list')\n",
    "for key in X.keys():\n",
    "    X[key]=np.array(X[key])\n",
    "prep=tf.keras.models.load_model('E:\\\\kyk-ml\\\\model\\\\DeepFM\\\\Preprocess')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cross validation and obtain the optimal model\n",
    "#model=dfm.cross_validation(X,y,epochs=8)\n",
    "#model.save('DeepFM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adapt the preprocessing layers and save\n",
    "\n",
    "#prep=dfm.Prep_model()\n",
    "#prep=dfm.train_prep_model(prep,X)\n",
    "#prep.save('Preprocess')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tensorboard and early stopping callbacks\n",
    "model=dfm.DeepFM()\n",
    "X_prep=prep(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_l=[X_prep[0],X_prep[3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/8\n",
      "139/139 [==============================] - 5s 19ms/step - loss: 236.2531 - auc_1: 0.6762 - recall_1: 0.8594 - val_loss: 0.6911 - val_auc_1: 0.4922 - val_recall_1: 0.4748\n",
      "Epoch 2/8\n",
      "139/139 [==============================] - 2s 16ms/step - loss: 0.4556 - auc_1: 0.8615 - recall_1: 0.8562 - val_loss: 0.6922 - val_auc_1: 0.4760 - val_recall_1: 0.4603\n",
      "Epoch 3/8\n",
      "139/139 [==============================] - 2s 16ms/step - loss: 0.2827 - auc_1: 0.9553 - recall_1: 0.9216 - val_loss: 0.6929 - val_auc_1: 0.4740 - val_recall_1: 0.4624\n",
      "Epoch 4/8\n",
      "139/139 [==============================] - 2s 16ms/step - loss: 0.1880 - auc_1: 0.9815 - recall_1: 0.9502 - val_loss: 0.6947 - val_auc_1: 0.4737 - val_recall_1: 0.4642\n",
      "Epoch 5/8\n",
      "139/139 [==============================] - 2s 16ms/step - loss: 0.1388 - auc_1: 0.9897 - recall_1: 0.9646 - val_loss: 0.6972 - val_auc_1: 0.4731 - val_recall_1: 0.4613\n",
      "Epoch 6/8\n",
      "139/139 [==============================] - 2s 16ms/step - loss: 0.1129 - auc_1: 0.9928 - recall_1: 0.9714 - val_loss: 0.6992 - val_auc_1: 0.4747 - val_recall_1: 0.4648\n",
      "Epoch 7/8\n",
      "139/139 [==============================] - 2s 16ms/step - loss: 0.0977 - auc_1: 0.9944 - recall_1: 0.9753 - val_loss: 0.7016 - val_auc_1: 0.4746 - val_recall_1: 0.4623\n",
      "Epoch 8/8\n",
      "139/139 [==============================] - 2s 16ms/step - loss: 0.0874 - auc_1: 0.9954 - recall_1: 0.9777 - val_loss: 0.7036 - val_auc_1: 0.4746 - val_recall_1: 0.4680\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x22c758b38b0>"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "#tensorboard=tf.keras.callbacks.TensorBoard(log_dir='E:\\\\Tensorboard\\\\DeepFM\\\\',write_graph=True)\n",
    "#earlystopping=tf.keras.callbacks.EarlyStopping(monitor='val_loss',verbose=1,patience=3,mode='min',restore_best_weights=True)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.01),loss=tf.keras.losses.BinaryCrossentropy(),metrics=[tf.keras.metrics.AUC(),tf.keras.metrics.Recall()])\n",
    "model.fit(X_l,y,batch_size=8192,epochs=8,validation_split=0.3,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_user=pd.read_csv('E:\\\\dataset\\\\sample_user.csv')\n",
    "result_set=[]\n",
    "for user_id in sample_user.user_id:\n",
    "    user_feature=dfm.get_users(user_id)\n",
    "    item_feature=dfm.get_items()\n",
    "    features=dict()\n",
    "    features.update(user_feature)\n",
    "    features.update(item_feature)\n",
    "    result=dfm.guess_you_like(deepfm,features,topK='all',json_like=False)\n",
    "    result_set.append(result)\n",
    "result_set=pd.concat(result_set,axis=0)\n",
    "engine_str='mysql+pymysql://kykviewer:$KykForView@keyikedb.mysql.rds.aliyuncs.com/wechat_finance_db'\n",
    "sql=\"select channel_id as user_id,phone from bigdata.chsell_quick_bi\"\n",
    "users=pd.read_sql(sql,engine_str)\n",
    "result_set=result_set.merge(users,on='user_id',how='inner')\n",
    "result_set.to_excel('sample_user_recommendation.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train item2vec model\n",
    "'''\n",
    "X=pd.read_csv('item_feature.csv')\n",
    "X=X.dropna()\n",
    "y=X.pop('label').values\n",
    "X=X.to_dict(orient='list')\n",
    "for key in X.keys():\n",
    "    X[key]=np.array(X[key])\n",
    "model=dfm.Item2vec(X)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.05),loss=tf.keras.losses.BinaryCrossentropy(),metrics=[tf.keras.metrics.Recall(),tf.keras.metrics.AUC(),tf.keras.metrics.Accuracy()])\n",
    "model.fit(X,y,epochs=20,verbose=2)\n",
    "'''\n",
    "#model.save('item2vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load item2vec model\n",
    "#calculate item similarity\n",
    "'''\n",
    "item_features=pd.read_csv('item_profile.csv')\n",
    "model=tf.keras.models.load_model('item2vec')\n",
    "writer=pd.ExcelWriter('sim.xlsx')\n",
    "for item in item_features['item_id'].unique():\n",
    "    sim=dfm.get_similar_items(model,item_features,item_id=item)\n",
    "    name=item_features.loc[item_features['item_id']==item,'item_name'].reset_index(drop=True)\n",
    "    item_id=[]\n",
    "    cos=[]\n",
    "    for key,value in sim['item_list'].items():\n",
    "        item_id.append(key)\n",
    "        cos.append(value)\n",
    "    dat=pd.DataFrame({'item_id':item_id,'sim':cos}).merge(item_features,on='item_id',how='inner').loc[:,['item_id','item_name','sim']]\n",
    "    dat.to_excel(excel_writer=writer,sheet_name=name[0],index=False)\n",
    "writer.save()\n",
    "writer.close()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write item vectors to tsv file for tensorflow projector\n",
    "'''\n",
    "weights=item_model.get_layer('id_embedding_layer').get_weights()[0]\n",
    "vocab=item_model.get_layer('id_vectorize').get_vocabulary()\n",
    "out_v=io.open('vecs.tsv','w',encoding='utf-8')\n",
    "out_m=io.open('meta.tsv','w',encoding='utf-8')\n",
    "for index,word in enumerate(vocab):\n",
    "    if index==0:continue\n",
    "    vec=weights[index]\n",
    "    out_v.write('\\t'.join([str(x) for x in vec])+'\\n')\n",
    "    out_m.write(word+'\\n')\n",
    "out_v.close()\n",
    "out_m.close()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}
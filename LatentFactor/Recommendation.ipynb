{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "celtic-dryer",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import LatentFactor\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import lightgbm as lgb\n",
    "from LatentFactor import RecommendList\n",
    "#from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix,recall_score,roc_curve,precision_score\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "distinct-jumping",
   "metadata": {},
   "outputs": [],
   "source": [
    "dftrain=pd.read_csv('train.csv')\n",
    "dftest=pd.read_csv('test.csv')\n",
    "item_pool=pd.read_csv('item_pool.csv')\n",
    "item_pool=list(item_pool['oper_obj'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "===============Iteration 0===============\n",
      "\n",
      "cross entropy loss: 0.643332014857206\n",
      "===============Iteration 1===============\n",
      "\n",
      "cross entropy loss: 0.566110612826628\n",
      "===============Iteration 2===============\n",
      "\n",
      "cross entropy loss: 0.4938021388316874\n",
      "===============Iteration 3===============\n",
      "\n",
      "cross entropy loss: 0.43558875511234085\n",
      "===============Iteration 4===============\n",
      "\n",
      "cross entropy loss: 0.38465554419698944\n",
      "===============Iteration 5===============\n",
      "\n",
      "cross entropy loss: 0.33741213912079737\n",
      "===============Iteration 6===============\n",
      "\n",
      "cross entropy loss: 0.2937469938898363\n",
      "===============Iteration 7===============\n",
      "\n",
      "cross entropy loss: 0.2570077921109922\n",
      "===============Iteration 8===============\n",
      "\n",
      "cross entropy loss: 0.22934136849541437\n",
      "===============Iteration 9===============\n",
      "\n",
      "cross entropy loss: 0.20906712218257298\n",
      "===============Iteration 10===============\n",
      "\n",
      "cross entropy loss: 0.19489804453754112\n",
      "===============Iteration 11===============\n",
      "\n",
      "cross entropy loss: 0.18310268754942188\n",
      "===============Iteration 12===============\n",
      "\n",
      "cross entropy loss: 0.17365861599962698\n",
      "===============Iteration 13===============\n",
      "\n",
      "cross entropy loss: 0.16662244706177046\n",
      "===============Iteration 14===============\n",
      "\n",
      "cross entropy loss: 0.16061101741958048\n",
      "===============Iteration 15===============\n",
      "\n",
      "cross entropy loss: 0.15536095362471877\n",
      "===============Iteration 16===============\n",
      "\n",
      "cross entropy loss: 0.15092055344980876\n",
      "===============Iteration 17===============\n",
      "\n",
      "cross entropy loss: 0.1462690684630368\n",
      "===============Iteration 18===============\n",
      "\n",
      "cross entropy loss: 0.14288949810019405\n",
      "===============Iteration 19===============\n",
      "\n",
      "cross entropy loss: 0.14034638042169445\n",
      "===============Iteration 20===============\n",
      "\n",
      "cross entropy loss: 0.13779913606640432\n",
      "===============Iteration 21===============\n",
      "\n",
      "cross entropy loss: 0.1352899439472178\n",
      "===============Iteration 22===============\n",
      "\n",
      "cross entropy loss: 0.13290678805151737\n",
      "===============Iteration 23===============\n",
      "\n",
      "cross entropy loss: 0.13084525116657894\n",
      "===============Iteration 24===============\n",
      "\n",
      "cross entropy loss: 0.12844086525795845\n",
      "===============Iteration 25===============\n",
      "\n",
      "cross entropy loss: 0.12741403450714606\n",
      "===============Iteration 26===============\n",
      "\n",
      "cross entropy loss: 0.1256601051279078\n",
      "===============Iteration 27===============\n",
      "\n",
      "cross entropy loss: 0.12434741937899269\n",
      "===============Iteration 28===============\n",
      "\n",
      "cross entropy loss: 0.12319399466860263\n",
      "===============Iteration 29===============\n",
      "\n",
      "cross entropy loss: 0.12144219778285478\n",
      "===============Iteration 30===============\n",
      "\n",
      "cross entropy loss: 0.1204290994117312\n",
      "===============Iteration 31===============\n",
      "\n",
      "cross entropy loss: 0.11930883883245672\n",
      "===============Iteration 32===============\n",
      "\n",
      "cross entropy loss: 0.11812512111842247\n",
      "===============Iteration 33===============\n",
      "\n",
      "cross entropy loss: 0.11729635251771788\n",
      "===============Iteration 34===============\n",
      "\n",
      "cross entropy loss: 0.11626030807049192\n",
      "===============Iteration 35===============\n",
      "\n",
      "cross entropy loss: 0.11553620937028379\n",
      "===============Iteration 36===============\n",
      "\n",
      "cross entropy loss: 0.1148779843429085\n",
      "===============Iteration 37===============\n",
      "\n",
      "cross entropy loss: 0.11424631960049378\n",
      "===============Iteration 38===============\n",
      "\n",
      "cross entropy loss: 0.11349315363585272\n",
      "===============Iteration 39===============\n",
      "\n",
      "cross entropy loss: 0.11300743479347843\n",
      "===============Iteration 40===============\n",
      "\n",
      "cross entropy loss: 0.1124601699781152\n",
      "===============Iteration 41===============\n",
      "\n",
      "cross entropy loss: 0.11149198874848164\n",
      "===============Iteration 42===============\n",
      "\n",
      "cross entropy loss: 0.11094811267827107\n",
      "===============Iteration 43===============\n",
      "\n",
      "cross entropy loss: 0.11035824232007636\n",
      "===============Iteration 44===============\n",
      "\n",
      "cross entropy loss: 0.10951818394469157\n",
      "===============Iteration 45===============\n",
      "\n",
      "cross entropy loss: 0.10923942723645717\n",
      "===============Iteration 46===============\n",
      "\n",
      "cross entropy loss: 0.10888911966693281\n",
      "===============Iteration 47===============\n",
      "\n",
      "cross entropy loss: 0.10855791115408042\n",
      "===============Iteration 48===============\n",
      "\n",
      "cross entropy loss: 0.10830476830113472\n",
      "===============Iteration 49===============\n",
      "\n",
      "cross entropy loss: 0.10767371593159508\n"
     ]
    }
   ],
   "source": [
    "#training Latent factor model, which generates embedding vectors for users and items.\n",
    "lf=LatentFactor.LatentFactor(F=32,item_pool=item_pool,neg_ratio=2,iters=50,eta=0.08,lamda=0.01,verbose=True)\n",
    "lf.fit(dftrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=lf.getDataset(dftrain,2)\n",
    "test=lf.getDataset(dftest,2)\n",
    "lgb_cols=[col for col in train.columns if col not in ['user_id','item_id','label']]\n",
    "lgbtrain=lgb.Dataset(train[lgb_cols],label=train['label'])\n",
    "lgbtest=lgb.Dataset(test[lgb_cols],label=test['label'])\n",
    "lgb_rank_X_train=train.sort_values(by=['user_id']).reset_index(drop=True)\n",
    "lgb_rank_X_test=test.sort_values(by=['user_id']).reset_index(drop=True)\n",
    "group_train=train.sort_values(by=['user_id']).groupby(['user_id'],as_index=False).count()['label'].values\n",
    "group_test=test.sort_values(by=['user_id']).groupby(['user_id'],as_index=False).count()['label'].values\n",
    "del train\n",
    "del test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[20]\ttest's ndcg@1: 0.309251\ttest's ndcg@2: 0.382827\ttest's ndcg@3: 0.448335\ttest's ndcg@4: 0.495412\ttest's ndcg@5: 0.526073\ttest's ndcg@6: 0.548468\ttest's ndcg@7: 0.566088\n",
      "[40]\ttest's ndcg@1: 0.309251\ttest's ndcg@2: 0.384279\ttest's ndcg@3: 0.449851\ttest's ndcg@4: 0.496267\ttest's ndcg@5: 0.52635\ttest's ndcg@6: 0.549742\ttest's ndcg@7: 0.566935\n",
      "[60]\ttest's ndcg@1: 0.367401\ttest's ndcg@2: 0.399735\ttest's ndcg@3: 0.461249\ttest's ndcg@4: 0.506674\ttest's ndcg@5: 0.536048\ttest's ndcg@6: 0.559053\ttest's ndcg@7: 0.576003\n",
      "[80]\ttest's ndcg@1: 0.346256\ttest's ndcg@2: 0.39592\ttest's ndcg@3: 0.463259\ttest's ndcg@4: 0.512747\ttest's ndcg@5: 0.538868\ttest's ndcg@6: 0.558341\ttest's ndcg@7: 0.575476\n",
      "[100]\ttest's ndcg@1: 0.365639\ttest's ndcg@2: 0.418853\ttest's ndcg@3: 0.483342\ttest's ndcg@4: 0.530455\ttest's ndcg@5: 0.554382\ttest's ndcg@6: 0.574638\ttest's ndcg@7: 0.589933\n",
      "[120]\ttest's ndcg@1: 0.390308\ttest's ndcg@2: 0.44939\ttest's ndcg@3: 0.506066\ttest's ndcg@4: 0.549361\ttest's ndcg@5: 0.571099\ttest's ndcg@6: 0.588612\ttest's ndcg@7: 0.605156\n",
      "[140]\ttest's ndcg@1: 0.405286\ttest's ndcg@2: 0.46376\ttest's ndcg@3: 0.517924\ttest's ndcg@4: 0.558998\ttest's ndcg@5: 0.578741\ttest's ndcg@6: 0.599544\ttest's ndcg@7: 0.614362\n",
      "[160]\ttest's ndcg@1: 0.405286\ttest's ndcg@2: 0.475957\ttest's ndcg@3: 0.524317\ttest's ndcg@4: 0.565577\ttest's ndcg@5: 0.587323\ttest's ndcg@6: 0.605691\ttest's ndcg@7: 0.619828\n",
      "[180]\ttest's ndcg@1: 0.410573\ttest's ndcg@2: 0.484132\ttest's ndcg@3: 0.53075\ttest's ndcg@4: 0.571808\ttest's ndcg@5: 0.595551\ttest's ndcg@6: 0.612189\ttest's ndcg@7: 0.625977\n",
      "[200]\ttest's ndcg@1: 0.41674\ttest's ndcg@2: 0.48881\ttest's ndcg@3: 0.536931\ttest's ndcg@4: 0.577275\ttest's ndcg@5: 0.598488\ttest's ndcg@6: 0.617264\ttest's ndcg@7: 0.629743\n",
      "[220]\ttest's ndcg@1: 0.421145\ttest's ndcg@2: 0.488984\ttest's ndcg@3: 0.54406\ttest's ndcg@4: 0.580846\ttest's ndcg@5: 0.603146\ttest's ndcg@6: 0.619137\ttest's ndcg@7: 0.633471\n",
      "[240]\ttest's ndcg@1: 0.43348\ttest's ndcg@2: 0.495991\ttest's ndcg@3: 0.548013\ttest's ndcg@4: 0.585489\ttest's ndcg@5: 0.60648\ttest's ndcg@6: 0.623136\ttest's ndcg@7: 0.637604\n",
      "[260]\ttest's ndcg@1: 0.440529\ttest's ndcg@2: 0.498824\ttest's ndcg@3: 0.54808\ttest's ndcg@4: 0.587626\ttest's ndcg@5: 0.607045\ttest's ndcg@6: 0.625484\ttest's ndcg@7: 0.639387\n",
      "[280]\ttest's ndcg@1: 0.436123\ttest's ndcg@2: 0.500858\ttest's ndcg@3: 0.549513\ttest's ndcg@4: 0.587415\ttest's ndcg@5: 0.608827\ttest's ndcg@6: 0.626725\ttest's ndcg@7: 0.639652\n",
      "[300]\ttest's ndcg@1: 0.438767\ttest's ndcg@2: 0.500847\ttest's ndcg@3: 0.551437\ttest's ndcg@4: 0.590759\ttest's ndcg@5: 0.610309\ttest's ndcg@6: 0.627508\ttest's ndcg@7: 0.641981\n",
      "[320]\ttest's ndcg@1: 0.449339\ttest's ndcg@2: 0.508872\ttest's ndcg@3: 0.554961\ttest's ndcg@4: 0.594494\ttest's ndcg@5: 0.612909\ttest's ndcg@6: 0.629911\ttest's ndcg@7: 0.645018\n",
      "[340]\ttest's ndcg@1: 0.449339\ttest's ndcg@2: 0.508011\ttest's ndcg@3: 0.55713\ttest's ndcg@4: 0.594671\ttest's ndcg@5: 0.615712\ttest's ndcg@6: 0.631379\ttest's ndcg@7: 0.645004\n",
      "[360]\ttest's ndcg@1: 0.451101\ttest's ndcg@2: 0.512464\ttest's ndcg@3: 0.556397\ttest's ndcg@4: 0.596036\ttest's ndcg@5: 0.618134\ttest's ndcg@6: 0.633534\ttest's ndcg@7: 0.647728\n",
      "[380]\ttest's ndcg@1: 0.452863\ttest's ndcg@2: 0.514352\ttest's ndcg@3: 0.557904\ttest's ndcg@4: 0.596544\ttest's ndcg@5: 0.618685\ttest's ndcg@6: 0.634562\ttest's ndcg@7: 0.648825\n",
      "[400]\ttest's ndcg@1: 0.454626\ttest's ndcg@2: 0.517566\ttest's ndcg@3: 0.559425\ttest's ndcg@4: 0.597709\ttest's ndcg@5: 0.619078\ttest's ndcg@6: 0.635281\ttest's ndcg@7: 0.650491\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[388]\ttest's ndcg@1: 0.457269\ttest's ndcg@2: 0.517268\ttest's ndcg@3: 0.56089\ttest's ndcg@4: 0.597655\ttest's ndcg@5: 0.619997\ttest's ndcg@6: 0.635928\ttest's ndcg@7: 0.650303\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LGBMRanker(boosting_type='goss', class_weight=None, colsample_bytree=0.6,\n",
       "           importance_type='split', learning_rate=0.015, max_depth=6,\n",
       "           min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
       "           n_estimators=400, n_jobs=-1, num_leaves=8, objective=None,\n",
       "           random_state=None, reg_alpha=0.1, reg_lambda=0.08, silent=True,\n",
       "           subsample=0.6, subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "#Lightgbm ranking model\n",
    "lgb_ranker=lgb.LGBMRanker(boosting_type='goss',n_estimators=400,num_leaves=8,min_child_weight=0.001,reg_alpha=0.1,reg_lambda=0.08,max_depth=6,subsample=0.6,colsample_bytree=0.6,learning_rate=0.015)\n",
    "lgb_ranker.fit(lgb_rank_X_train[lgb_cols],lgb_rank_X_train['label'],group=group_train,eval_set=[(lgb_rank_X_test[lgb_cols],lgb_rank_X_test['label'])],eval_names=['test'],eval_metric='ndcg',eval_at=[1,2,3,4,5,6,7],eval_group=[group_test],early_stopping_rounds=100,verbose=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.008, min_child_weight=0.006 will be ignored. Current value: min_sum_hessian_in_leaf=0.008\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.008, min_child_weight=0.006 will be ignored. Current value: min_sum_hessian_in_leaf=0.008\n",
      "[LightGBM] [Info] Number of positive: 110949, number of negative: 150462\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.050402 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 11072\n",
      "[LightGBM] [Info] Number of data points in the train set: 261411, number of used features: 64\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.424424 -> initscore=-0.304640\n",
      "[LightGBM] [Info] Start training from score -0.304640\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\ttrain's auc: 0.935222\ttest's auc: 0.6054\n",
      "[400]\ttrain's auc: 0.969951\ttest's auc: 0.618107\n",
      "[600]\ttrain's auc: 0.980758\ttest's auc: 0.623208\n",
      "[800]\ttrain's auc: 0.985515\ttest's auc: 0.626485\n",
      "[1000]\ttrain's auc: 0.98834\ttest's auc: 0.627838\n",
      "[1200]\ttrain's auc: 0.990186\ttest's auc: 0.62875\n",
      "Early stopping, best iteration is:\n",
      "[1215]\ttrain's auc: 0.990288\ttest's auc: 0.629028\n"
     ]
    }
   ],
   "source": [
    "#lightgbm binary classification\n",
    "eval_result={}\n",
    "clf_params={'objective':'binary','metric':'auc','boosting':'goss','eta':0.05,'num_leaves':12,'max_depth':6,\n",
    "        'min_sum_hessian_in_leaf':0.002,'subsample':0.6,'colsample_bytree':0.6,'reg_alpha':0.2,'reg_lambda':0.08,'is_unbalance':True}\n",
    "lgb_clf=lgb.train(clf_params,lgbtrain,num_boost_round=1500,early_stopping_rounds=100,valid_sets=[lgbtrain,lgbtest],valid_names=['train','test'],verbose_eval=200,evals_result=eval_result)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predictions and the ground trueth\n",
    "result_rank=RecommendList(lgb_rank_X_test,lgb_ranker,lgb_cols)\n",
    "result_clf=RecommendList(lgb_rank_X_test,lgb_clf,lgb_cols)\n",
    "result_true=RecommendList(lgb_rank_X_test,lgb_ranker,lgb_cols,is_predict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.25219717233473443\n",
      "0.30855941918226976\n"
     ]
    }
   ],
   "source": [
    "#Performance\n",
    "rank_pred=result_rank.melt(id_vars=['user_id']).dropna().drop(columns='variable').rename(columns={'user_id':'agent_id','value':'oper_obj'})\n",
    "clf_pred=result_clf.melt(id_vars=['user_id']).dropna().drop(columns='variable').rename(columns={'user_id':'agent_id','value':'oper_obj'})\n",
    "print(lf.Recall(dftest,rank_pred))\n",
    "print(lf.Recall(dftest,clf_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}